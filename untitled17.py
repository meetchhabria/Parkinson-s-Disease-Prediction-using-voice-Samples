# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L3xZMMpFdzR0aQfROm4N8XapDPUfUQYY
"""

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, KFold, GridSearchCV
from sklearn.metrics import confusion_matrix
import joblib

class ParkinsonClassifier:
    def __init__(self):
        self.model = None

    def train(self, dataset):
        # Data Cleaning
        dataset = dataset.dropna()
        dataset = dataset.iloc[:-1500]
        dataset = dataset.sample(frac=1, random_state=42)

        X = dataset.drop(['label'], axis=1)
        y = dataset['label']

        # Training the model
        self.model = DecisionTreeClassifier(max_depth=3, min_samples_split=2, min_samples_leaf=2, max_features='sqrt')
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)
        self.model.fit(X_train, y_train)

        # Evaluating the model
        X_test_prediction = self.model.predict(X_test)
        test_data_accuracy = accuracy_score(X_test_prediction, y_test)
        print("Test Data Accuracy:", test_data_accuracy * 100)

        conf_matrix = confusion_matrix(y_test, X_test_prediction)
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Greens", cbar=False)
        plt.title("Confusion Matrix")
        plt.xlabel("Predicted Labels")
        plt.ylabel("True Labels")
        plt.show()

        # Performing cross validation
        num_folds = 5
        kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)
        scores = cross_val_score(self.model, X, y, cv=kf, scoring='accuracy')
        print("Cross-Validation Scores:", scores)
        print("Mean Accuracy:", scores.mean())
        print("Standard Deviation:", scores.std())

        # Hyperparameter tuning
        param_grid = {
            'max_depth': [3, 5, 7],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2']
        }
        grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=kf, scoring='accuracy')
        grid_search.fit(X, y)
        results_df = pd.DataFrame(grid_search.cv_results_)
        print(results_df[['params', 'mean_test_score']])
        print("Best Hyperparameters:", grid_search.best_params_)

    def predict(self, input_data):
        if self.model is None:
            print("Error: Model not trained.")
            return None
        else:
            input_data_array = np.asarray(input_data)
            input_data_reshaped = input_data_array.reshape(1, -1)
            prediction = self.model.predict(input_data_reshaped)
            if prediction[0] == 0:
                return 'The person does not have Parkinson\'s disease'
            else:
                return 'The person has Parkinson\'s disease'

# Load the datasets
dataset1 = pd.read_csv('with_mfcc.csv')
dataset2 = pd.read_csv('without_mfcc.csv')
dataset3 = pd.read_csv('without1.csv')
dataset4 = pd.concat([dataset3, dataset2], ignore_index=True)
dataset = pd.concat([dataset1, dataset4], ignore_index=True)

# Initialize and train the classifier
classifier = ParkinsonClassifier()
classifier.train(dataset)

# Example usage of the predict method
input_data = [-283.52698, 98.99438, -3.029233, -6.9686766, -2.1753619, -35.71373, -31.066952, -14.886692,
              -1.1284362, -11.66128, 1.869652, -0.84416664, -1.6005697]
print(classifier.predict(input_data))

# Save the trained model to a file
joblib.dump(classifier.model, 'decision_tree_model.pkl')